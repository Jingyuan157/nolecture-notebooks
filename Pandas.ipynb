{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is Pandas?\n",
        "---\n",
        "\n",
        "From https://pandas.pydata.org/pandas-docs/stable:\n",
        "\n",
        "> pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with \u201crelational\u201d or \u201clabeled\u201d data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.\n",
        ">\n",
        "> pandas is well suited for many different kinds of data:\n",
        ">\n",
        "> - Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n",
        "> - Ordered and unordered (not necessarily fixed-frequency) time series data.\n",
        "> - Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n",
        "> - Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure\n",
        "\n",
        "Why would you want to choose Pandas over a spreadsheet program (e.g. Excel)?\n",
        "\n",
        "- Pandas is open-source and free \ud83d\udc4d\n",
        "- One can store __reproducible__ steps to get from an input to an output\n",
        "    - Excel will only store the final state, not the steps to get there!\n",
        "- It is less memory intensive and you can work with larger datasets\n",
        "- It is fast and libraries exist (e.g. dask, ray, RAPIDS) to scale far beyond one core\n",
        "\n",
        "### Pandas is built with NumPy\n",
        "\n",
        "NumPy provides multi-dimensional list-like data structures which are __typed__ and much faster than Python lists. The interface to the pandas data structures, to be discussed in this workshop, is very similar to the one provided by NumPy. In many cases the methods provided have the same, or similar, names. Therefore, I will skip a detailed discussion of NumPy and simply point you to the [documentation](https://docs.scipy.org/doc/numpy/reference/) for later use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing Pandas\n",
        "---\n",
        "\n",
        "First, you need to `import pandas`. By convention, it is imported using the _alias_ `pd`. To import using an alias use the following syntax:\n",
        "\n",
        "```python\n",
        "import <library> as <alias>\n",
        "```\n",
        "\n",
        "- Many popular libraries try to define an alias convention, check their documentation\n",
        "\n",
        "#### Tasks:\n",
        "\n",
        "1. Try to import `pandas` using the alias convention?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Structures\n",
        "---\n",
        "\n",
        "Similar to the Python data structures (e.g. `list, dictionary, set`), Pandas provides three fundamental data structures:\n",
        "\n",
        "1. `Series`: For one-dimensional data, similar to a Python list\n",
        "2. `DataFrame`: For two-dimensional data, similar to a Python list of lists\n",
        "3. `Index`: Similar to a `Series`, but for naming, selecting, and transforming data within a `Series` or `DataFrame`\n",
        "\n",
        "### Series\n",
        "\n",
        "You can create a Pandas `Series` in a variety of ways, e.g.:\n",
        "\n",
        "- From an assigned Python list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = ['a', 'b', 'c']\n",
        "series = pd.Series(a)\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- From an unnamed Python list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series([4, 5, 6])\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Using a specific index (similar to a `dict` where `index` are the keys):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series([4, 5, 6], index=[\"a\", \"b\", \"c\"])\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Directly from a dictionary (exactly the same as above):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "series = pd.Series({\"a\": 4, \"b\": 5, \"c\": 6})\n",
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataFrame\n",
        "\n",
        "This is the data structure that makes Pandas shine. A `DataFrame` is essentially a dictionary of `Series` objects. In a `DataFrame`, the `keys` map to `Series` objects which share a common `index`. We should start with an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rock_bands = [\"Pink Floyd\", \"Rush\", \"Yes\"]\n",
        "year_formed = [1965, 1968, 1968]\n",
        "location_formed = [\"London, England\", \"Ontario, Canada\", \"London, England\"]\n",
        "df = pd.DataFrame({\"year_formed\": year_formed, \"location_formed\": location_formed}, index=rock_bands)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Breaking Down the Result\n",
        "\n",
        "- The indicies are `\"Pink Floyd\"`, `\"Rush\"`, and `\"Yes\"`\n",
        "- The keys to the DataFrame are `\"year_formed\"` and `\"location_formed\"`\n",
        "- The lists are converted to `Series` objects which share the indices\n",
        "\n",
        "This might not seem very powerful, except that `DataFrame`s can be constructed from files! In a previous task, you were asked to read a file `states.csv` then parse it manually and do some statistics. In the following cell, I will read the file and generate statistics in two lines!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"states.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Use `pd.read_csv` to read in the csv file: `example.bsv`\n",
        "    - It does not contain a header (add `header=None` to the arguments)\n",
        "    - When working with a single dataframe it is assigned to the name `df`, by convention\n",
        "    - The file is bar separated (add `sep='|'` to the arguments)\n",
        "    - Lastly set the column names (add `names=[\"First\", \"Second\"]`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viewing DataFrames\n",
        "---\n",
        "\n",
        "Jupyter has built in support for viewing `DataFrame` objects in a nice format. Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([0, 1, 2], index=[5, 6, 7], columns=[\"Example\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result should have been a nice looking table. Reminders:\n",
        "\n",
        "- The above `DataFrame` contains a single `Series` with the key `Example`\n",
        "- The indices are on the left (in bold)\n",
        "- The values are in columns underneath the key\n",
        "\n",
        "If you only want to view a subset of the DataFrame, you can use the syntax `<df>.head()`. By default it will print only 5 rows from the top of your DataFrame. This is very useful when trying to view the _shape_ of your data. You can print fewer rows by adding `n=<number>` to the arguments of `head`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell below\n",
        "- Print the DataFrame in the following ways:\n",
        "    - Using the built in Jupyter view\n",
        "    - The head\n",
        "    - The first row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "l = list(range(10))\n",
        "df = pd.DataFrame({\"a\": l, \"b\": l, \"c\": l})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Access and Types\n",
        "\n",
        "You can access individual `Series` from `DataFrame`s using two syntax:\n",
        "\n",
        "- Like a dictionary: `<df>[\"<key>\"]`\n",
        "- Like a data member, `<df>.<key>`\n",
        "\n",
        "Important notes about the data member style:\n",
        "\n",
        "- doesn't support keys with spaces\n",
        "- can't be used to assign values to a non-existent key\n",
        "\n",
        "For these reasons, I tend to prefer the dictionary style for everything. You will see both styles in this document simply to increase your familiarity with both, but it is important to know the limitations.\n",
        "\n",
        "If you want to know the types of your `DataFrame`'s `Series`s using `<df>.dtypes`\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell below\n",
        "- Access the `b` Series of `df` using both accessor syntax\n",
        "- Why are two columns printed?\n",
        "- What is the type of `df[\"b\"]`?\n",
        "- What are the `dtypes` of `df`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "df = pd.DataFrame({\"a\": [0, 1, 2], \"b\": [0.0, 1.0, 2.0], \"c\": [\"pandas\", \"is\", \"great\"]})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Slicing and Indexing\n",
        "---\n",
        "\n",
        "There are many ways to slice and dice DataFrames. Let's start with the least flexible option, selecting multiple columns. Let's make a new DataFrame in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n",
        "example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To slice columns `a` and `c` we'll use a similar syntax to dictionary access, shown before, but instead we will ask for a list of columns instead of a single one, e.g. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example[[\"a\", \"c\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can also slice rows using the `list` slicing syntax. Note you are __required__ to specify a slice (something containing '`:`'). For example,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zeroth row only\n",
        "example[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first row to end\n",
        "example[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# every other row\n",
        "example[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this will fail with `KeyError`\n",
        "# -> remember this is dictionary style access and `0` isn't a key!\n",
        "example[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More Complicated Access Patterns\n",
        "---\n",
        "\n",
        "You can narrow down rows and columns using `loc`, some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only row 1, columns 'a' and 'c'\n",
        "example.loc[1:1, [\"a\", \"c\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all rows, columns 'a' to 'b'\n",
        "example.loc[:, \"a\":\"b\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# single row, single column\n",
        "example.loc[0, \"a\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "Using `loc` and the `example` DataFrame,\n",
        "\n",
        "1. Run the definitions cell below\n",
        "2. Try to print every other row\n",
        "3. Try to print columns `b` to `c`\n",
        "4. Try to print all columns of the final row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "example = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note\n",
        "\n",
        "`loc` is all about index/key access, what if the indices are characters? Run the following cell and then complete the tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example2 = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]}, index=[\"A\", \"B\", \"C\"])\n",
        "example2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "Use `loc` and DataFrame `example2`, to\n",
        "\n",
        "- Print rows `B` to `C` and columns `a` to `b`.\n",
        "- What happens if you try to access the index numerically?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "To access `example2` w/ numerical indices, we need `iloc`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. Using `iloc` and `example2`, get rows `B` to `C` and columns `a` to `b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "You can also use the `list` style access I showed before, e.g."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example2.iloc[[1, 2], [0, 1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access by Boolean Arrays\n",
        "---\n",
        "\n",
        "- One can use a boolean array to access subsets of `DataFrame`s\n",
        "- First, I will define a `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"hello\": [0, 1, 2], \"world\": [3, 4, 5]}, index=[\"top\", \"middle\", \"bottom\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- I can generate a boolean array using _dispatch_\n",
        "\n",
        "Aside: Dispatch\n",
        "---\n",
        "\n",
        "Dispatch is automatically used when you use the built-in operators, e.g. `==`. It essentially creates a new `Series` where it distributes the function to every element in the original `Series`. We should start with an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.index == \"middle\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The concept of dispatch can be a little tricky, what is the type and dtype?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = (df.index == \"middle\")\n",
        "type(arr), arr.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- One can use these `bool` arrays to downselect `DataFrame`s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.index == \"middle\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- You can also compose multiple criterion together, e.g.\n",
        "    - `|` is `or`\n",
        "    - `&` is `and`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[(df.index == \"middle\") | (df.index == \"top\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Access the `DataFrame` where column `\"a\"` is greater than or equal to 2\n",
        "- Access row `\"B\"` where row `\"B\"` is greater than or equal to 5\n",
        "- Access the `DataFrame` where column `\"a\"` is greater than 2 and column `\"b\"` is less than or equal to 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]}, index=[\"A\", \"B\", \"C\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Built-in Statistics\n",
        "---\n",
        "\n",
        "Coming back to the original example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = pd.read_csv(\"states.csv\", index_col=0)\n",
        "states.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- One can easily access the statistics of the entire `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- There are 52 states according to the `count`. The `mean` population is about 6.3 million people for 2016 and 2017\n",
        "- It is also possible to down select the statistics, e.g. if I want the mean for the key `Population (2016)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states[\"Population (2016)\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "- Find the state with\n",
        "    - the minimum (`min`) population in 2016\n",
        "    - the maximum (`max`) population in 2017"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding New Columns\n",
        "---\n",
        "\n",
        "How would we find the average population _per state_ for 2016 and 2017?\n",
        "\n",
        "- We can use a dispatched operation similar to the `==` example previous to generate the averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(states[\"Population (2016)\"] + states[\"Population (2017)\"]) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The above is a `Series` object. We can assign it to a `key` in the `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states[\"Average Population\"] = (states[\"Population (2016)\"] + states[\"Population (2017)\"]) / 2\n",
        "states[\"Average Population\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Finally the overall mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states[\"Average Population\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viewing Data\n",
        "---\n",
        "\n",
        "Pandas plugs into `matplotlib` very nicely. I am going to iteratively build a plot which is easy to read. First, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "states = pd.read_csv(\"states.csv\", index_col=0)\n",
        "states.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is something, but not very helpful. What would we like:\n",
        "\n",
        "- X axis should be labeled with the state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes\n",
        "---\n",
        "\n",
        "1. `subplots=True`: separates the 2 plots from one another\n",
        "2. `xticks=range(states.shape[0])`: sets all of the ticks on the x-axis\n",
        "3. `ax = ...`: is a list containing both plots\n",
        "4. `ax[0].set_xticklables` changes the numeric index to the State name, should only be necessary for the 0th plot\n",
        "5. `suppressing_output = ...`, I use this to supress the output from `set_xticklabels`\n",
        "\n",
        "\n",
        "Neat, but I can't read the labels..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]), figsize=(20, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The line plots are a little awkward because the points aren't connected in anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = states.plot(subplots=True, xticks=range(states.shape[0]), figsize=(20, 10), kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply + Lambda\n",
        "---\n",
        "\n",
        "I want to briefly show you a decent idiom for doing more complicated work on a `Series` object.\n",
        "\n",
        "This is a contrived example, but it shows the utility of `apply` + `lambda`. What if we wanted wanted to figure out if all letters A-Z are in the names of the states? First, we could create a `set` of characters in each state's name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# don't use the names of states an the index!\n",
        "states = pd.read_csv(\"states.csv\")\n",
        "\n",
        "def set_of_chars(s):\n",
        "    return set(list(s.lower()))\n",
        "\n",
        "series_of_sets = states.State.apply(lambda s: set_of_chars(s))\n",
        "series_of_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reminder: Lambdas\n",
        "---\n",
        "\n",
        "Reminder, a _lambda_ constructs an ephemeral unnamed function. This is opposed to the named function `set_of_chars` above. The point is the `apply` method takes a function. We could have done the following:\n",
        "\n",
        "```\n",
        "series_of_sets = states.State.apply(lambda s: set(list(s.lower())))\n",
        "```\n",
        "\n",
        "Or, simply:\n",
        "\n",
        "```\n",
        "series_of_sets = states.State.apply(set_of_chars)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting Back to the Problem\n",
        "---\n",
        "\n",
        "Now we have a `Series` of `set`s each containing the unique characters contained in each state's name. Next, we need to combine all of these sets into a single one!\n",
        "\n",
        "- First, an example of combining sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = {1, 2, 3}\n",
        "b = {2, 4}\n",
        "a.union(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we are going to __reduce__ the `Series` of `set`s by taking the union of each entry. If done step by step:\n",
        "\n",
        "```python\n",
        "_tmp = <zeroth_set>.union(<first_set>)\n",
        "_tmp = _tmp.union(<second_set>)\n",
        "_tmp = _tmp.union(<third_set>)\n",
        "...\n",
        "_tmp = _tmp.union(<final_set>)\n",
        "```\n",
        "\n",
        "Imagine if we had a million rows! Luckily, Python includes functions for this! It is called `reduce` and comes from the `functools` package.\n",
        "All we need to do is provide a function which combines two elements and it will recursively apply the function until there is only one value.\n",
        "Try the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "chars_used_in_states_name = reduce(lambda x, y: x.union(y), series_of_sets)\n",
        "chars_used_in_states_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we need to remove any non-alphanumeric characters\n",
        "\n",
        "- `ascii_lowercase` from `string` is simply a string of all of the characters\n",
        "    - We can test if something is part of this set by using the `in` function, try the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from string import ascii_lowercase\n",
        "print(\" \" in ascii_lowercase) # Should print `False`\n",
        "print(\"a\" in ascii_lowercase) # Should print `True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We can use a set comprehension to filter the non-ascii characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chars_used_in_states_name = {x for x in chars_used_in_states_name if x in ascii_lowercase}\n",
        "chars_used_in_states_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now we can answer our question!\n",
        "\n",
        "Are all of the characters used in the states names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alphabet_set = set(list(ascii_lowercase))\n",
        "alphabet_set.difference(chars_used_in_states_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The concepts of reductions and anonymous functions can be very useful when doing data analysis! Many times you can use comprehensions to do something similar, but I personally enjoy the `reduce` style. No tasks for this section. I would suggest prodding the above code to make sure you understand it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Built-in Methods and Axis\n",
        "---\n",
        "\n",
        "There are many built-in methods in Pandas, for example `.mean()`. By default, these methods operate on the columns with an argument called the `axis` with a default value of `0`. You can generate row based means with `axis=1`.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Generate the column and row means for `states` using the axis argument\n",
        "- Generate the DataFrame mean, i.e. a single value, for `states`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "states = pd.read_csv(\"states.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Writing Files\n",
        "---\n",
        "\n",
        "CSV files are a standard way to share data, one can write a `DataFrame` to a CSV file using the syntax:\n",
        "\n",
        "```python\n",
        "<df>.to_csv(<filename.csv>)\n",
        "```\n",
        "\n",
        "Notes:\n",
        "\n",
        "- The seperator, by default, is a comma. Try `sep=\"|\"` argument, use a '.bsv' ending\n",
        "- To not include the index, use `index=None`\n",
        "- To not include a header, use `header=None`\n",
        "\n",
        "### Tasks\n",
        "\n",
        "- Run the definitions cell\n",
        "- Write the `states` DataFrame to a file called \"intro.bsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "states = pd.read_csv(\"states.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining DataFrames\n",
        "---\n",
        "\n",
        "### Merge\n",
        "\n",
        "A `merge` operation takes two dataframes and tries to combine them side by side. We should start with a basic example. The names below are first names for current Vancouver Canucks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left = pd.DataFrame({\"id\": [1, 2, 3], \"names\": [\"Elias\", \"Jake\", \"Bo\"]})\n",
        "left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "right = pd.DataFrame({\"id\": [1, 2, 3], \"names\": [\"Brock\", \"Quinn\", \"Nikolay\"]})\n",
        "right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The keyword `on` takes a column from both dataframes and creates a new `DataFrame` sharing that column. Notice how the overlapping columns from the left Dataframe changed from `names` to `names_x` and the right to `names_y`. By default it will only merge columns where values are shared between the `DataFrame`s, i.e. an _inner join_. Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left = pd.DataFrame({\"id\": [1, 3], \"names\": [\"Elias\", \"Bo\"]})\n",
        "right = pd.DataFrame({\"id\": [1, 2], \"names\": [\"Brock\", \"Quinn\"]})\n",
        "pd.merge(left, right, on=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are a few different choices for _how_ you can join two `DataFrame`s\n",
        "\n",
        "- Using the keys from the `left` `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Using the keys from the `right` `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"id\", how=\"right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Use all of the keys, an `outer` join:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"id\", how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concatenate\n",
        "\n",
        "`concat` is used to stack `DataFrame`s on top of one-another. It takes a list of `DataFrame`s. Let's look at a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top    = pd.DataFrame({\"letters\": [\"a\", \"b\", \"c\"], \"numbers\": [1, 2, 3]})\n",
        "bottom = pd.DataFrame({\"letters\": [\"g\", \"h\", \"i\"], \"numbers\": [7, 8, 9]})\n",
        "pd.concat([top, bottom])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Run the definitions cell below\n",
        "2. Try to merge `top` and `middle` using an `outer` join on the `\"numbers\"` column\n",
        "3. Guess what will happen if you do an `inner` join? Test your hypothesis\n",
        "4. Try to concatenate `top`, `middle`, and `bottom`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# definitions\n",
        "top    = pd.DataFrame({\"letters\": [\"a\", \"b\", \"c\"], \"numbers\": [1, 2, 3]})\n",
        "middle = pd.DataFrame({\"letters\": [\"d\", \"e\", \"f\"], \"numbers\": [4, 5, 6]})\n",
        "bottom = pd.DataFrame({\"letters\": [\"g\", \"h\", \"i\"], \"numbers\": [7, 8, 9]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshaping DataFrames\n",
        "---\n",
        "\n",
        "### Grouping Data\n",
        "\n",
        "Let's work with some real data from Pittsburgh in this example. I got this data from [Western Pennslyvania Regional Data Center](http://www.wprdc.org/). First, we should get an idea of the shape of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"311.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This data was collected by the city of Pittsburgh from 311 calls. We are going to use the `groupby` functionality to extract some information from this data.\n",
        "\n",
        "I want you to extract some data for your neighborhood. First we will create a `groupby` object for the column `\"NEIGHBORHOOD\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neighborhood = df.groupby(by=\"NEIGHBORHOOD\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To get the groups, you can use the `groups` data member.\n",
        "- We can determine the number of 311 calls from each group by using the `count` method on the grouped `DataFrame` (I use head below to reduce the amount of output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neighborhood.count().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Select one of the columns from the grouped `DataFrame` and print the counts for all neighborhoods\n",
        "2. Did your neighborhood make the list?\n",
        "3. Which neighborhood has the most 311 calls?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the neighborhood with the most 311 calls, lets group again by the `\"REQUEST_TYPE\"`\n",
        "\n",
        "To get a group from a `DataFrame` you can use the `get_group` method, example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neighborhood.get_group(\"Allegheny Center\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Using the `get_group` and `groupby` functions, downselect the `neighborhood` `DataFrame` to the neighborhood with the most 311 calls and determine how many different types of requests were made"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- If we wanted to see all 311 calls for a particular neighborhood and request type we could simply make a groupby object for both columns!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "requests_by_neighborhood = df.groupby(by=[\"NEIGHBORHOOD\", \"REQUEST_TYPE\"])\n",
        "requests_by_neighborhood.get_group((\"Allegheny Center\", \"Potholes\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Grouping is very useful when you want to aggregrate based on duplicate entries\n",
        "\n",
        "### Pivoting\n",
        "\n",
        "- We can use pivoting to change the shape of our data. For example, if we wanted the police zones as our columns and neighborhood as our values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "police_zones = df.pivot(values=\"NEIGHBORHOOD\", columns=\"POLICE_ZONE\")\n",
        "police_zones.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now we have a new `DataFrame` with a few columns: `nan`, `1.0`, `2.0`, `3.0`, `4.0`, `5.0`, and `6.0`\n",
        "- My guess is the `nan` is because there are cases where the police zone is not specified, let's remove it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "police_zones = police_zones.iloc[:, 1:]\n",
        "police_zones.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- For each column, let's get the unique entries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in police_zones.columns:\n",
        "    print(col)\n",
        "    print(police_zones[col].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dealing with Strings\n",
        "---\n",
        "\n",
        "If your working with string data there is a special method which allows you to apply normal string methods on the entire column.\n",
        "\n",
        "This data set comes from the city of Pittsburgh. It is all of the trees that the city maintains. The dataset can be found at https://data.wprdc.org/dataset/city-trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"trees.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, a very simple example where we convert the `\"street\"` columns to lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"street\"].str.lower().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tasks\n",
        "---\n",
        "\n",
        "Strings have a `split` method. Given a string it will split the string up by that character into a list of strings. An example, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"Maple: Red\".split(\":\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Generate a `Series` which contains the tree type, in the above example `\"Maple\"`. Hint: use the `str` method and a `lambda`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Working with Categorical Variables\n",
        "---\n",
        "\n",
        "The dataset we will work with is information about Science Technology Enginnering and Math programs at different postsecondary institutions in Pennsylvania.\n",
        "\n",
        "We can first open the dataset and view all of the columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"stem.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's explore the dataset a bit. The `Type` column is a categorical variable. Let's look at what categories are available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Type\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything that isn't a `Community College` is considered a University. We can use `np.where` to fill in a new column of the dataframe, using the following syntax:\n",
        "\n",
        "```python\n",
        "np.where(<condition>, <true_value>, <false_value>)\n",
        "```\n",
        "\n",
        "For example,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Corrected Type\"] = np.where(df[\"Type\"] == \"Community College\", \"College\", \"University\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Try using `np.where` to create a new column `IsCollege` where the value is `True` for a college and `False` for a university.\n",
        "2. Try using the apply + lambda style to create a new column `IsUniversity` where the value is `True` for a university and `False` for a college.\n",
        "    - Hint: An inline `if-then-else` looks a bit different than we have seen previously, syntax:\n",
        "    \n",
        "    ```python\n",
        "    <true_value> if <condition> else <false_value>\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These columns are really useful because they act as boolean masks! Try the following cells:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df[\"IsCollege\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df[\"IsUniversity\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes\n",
        "---\n",
        "\n",
        "`np.where` and `if-then-else` will only work with two categories! If there are more than two categories we need to create more complicated boolean masks. Let's look an example using the Trees dataset from before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"trees.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's poke around the height data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"height\"].min(), df[\"height\"].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupby(\"height\").count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Height is a continuous variable ranging from 0 to 65. Let's convert this continuous variable into a categorical one with four ranges:\n",
        "\n",
        "- less than or equal to 15\n",
        "- greater than 15 and less than or equal to 30\n",
        "- greater than 30 and less than or equal to 45\n",
        "- greater than 45\n",
        "\n",
        "To do this we can create boolean masks and use them to fill in our categories, e.g."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask0 = df[\"height\"] <= 15\n",
        "mask1 = (df[\"height\"] > 15) & (df[\"height\"] <= 30)\n",
        "mask2 = (df[\"height\"] > 30) & (df[\"height\"] <= 45)\n",
        "mask3 = (df[\"height\"] > 45) & (df[\"height\"] <= 65)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "- Take a look at some of the masks just to make sure you see what they look like\n",
        "- The `(<condition>) & (<condition>)` syntax behaves like a broadcasted version of `<bool> and <bool>` (e.g. `True and True`), try the following code if you are still unsure. Make sure to think about what the answer should be before running it!\n",
        "    ```python\n",
        "    a = np.array([True, False, True])\n",
        "    b = np.array([True, False, False])\n",
        "    a & b\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[mask0, \"height_range\"] = \"0-15\"\n",
        "df.loc[mask1, \"height_range\"] = \"15-30\"\n",
        "df.loc[mask2, \"height_range\"] = \"30-45\"\n",
        "df.loc[mask3, \"height_range\"] = \"45-65\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\"height\", \"height_range\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "1. Try creating categorical ranges for width. Use three ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quick Survey\n",
        "---\n",
        "\n",
        "- `<Ctrl-Enter>` the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(\"https://forms.gle/N3h1vUYWneHs9Rkf8\", width=760, height=500)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
